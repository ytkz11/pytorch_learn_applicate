{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3453868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.autograd主要功能是完成神经网络后向传播中的链式求导\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17af5948",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Variable(torch.randn(batch_n, input_data),requires_grad = False)\n",
    "y = Variable(torch.randn(batch_n, output_data),requires_grad = False)\n",
    "\n",
    "w1 = Variable(torch.randn(input_data, hidden_layer),requires_grad = True)\n",
    "w2 = Variable(torch.randn(hidden_layer, output_data),requires_grad = True)\n",
    "epoch_n = 20\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea8d386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义总次数和学习率\n",
    "epoch_n = 200\n",
    "learning_rate = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60838e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,Loss:57908540.0000\n",
      "Epoch:1,Loss:142486304.0000\n",
      "Epoch:2,Loss:527324992.0000\n",
      "Epoch:3,Loss:662480768.0000\n",
      "Epoch:4,Loss:6516735.0000\n",
      "Epoch:5,Loss:4637657.0000\n",
      "Epoch:6,Loss:3483121.7500\n",
      "Epoch:7,Loss:2724824.7500\n",
      "Epoch:8,Loss:2202987.0000\n",
      "Epoch:9,Loss:1830444.0000\n",
      "Epoch:10,Loss:1555547.2500\n",
      "Epoch:11,Loss:1347215.0000\n",
      "Epoch:12,Loss:1185564.7500\n",
      "Epoch:13,Loss:1056872.0000\n",
      "Epoch:14,Loss:952119.5625\n",
      "Epoch:15,Loss:865328.1250\n",
      "Epoch:16,Loss:792113.8125\n",
      "Epoch:17,Loss:729491.8125\n",
      "Epoch:18,Loss:675129.6250\n",
      "Epoch:19,Loss:627432.0625\n",
      "Epoch:20,Loss:585171.5625\n",
      "Epoch:21,Loss:547466.8750\n",
      "Epoch:22,Loss:513550.1875\n",
      "Epoch:23,Loss:482901.3438\n",
      "Epoch:24,Loss:455036.0000\n",
      "Epoch:25,Loss:429556.0312\n",
      "Epoch:26,Loss:406169.8750\n",
      "Epoch:27,Loss:384643.5312\n",
      "Epoch:28,Loss:364772.4375\n",
      "Epoch:29,Loss:346357.6250\n",
      "Epoch:30,Loss:329315.9375\n",
      "Epoch:31,Loss:313536.9375\n",
      "Epoch:32,Loss:298863.9062\n",
      "Epoch:33,Loss:285182.2500\n",
      "Epoch:34,Loss:272448.6250\n",
      "Epoch:35,Loss:260537.2188\n",
      "Epoch:36,Loss:249370.7344\n",
      "Epoch:37,Loss:238889.7031\n",
      "Epoch:38,Loss:229039.3438\n",
      "Epoch:39,Loss:219767.1719\n",
      "Epoch:40,Loss:211032.6250\n",
      "Epoch:41,Loss:202801.9375\n",
      "Epoch:42,Loss:195046.2344\n",
      "Epoch:43,Loss:187731.8438\n",
      "Epoch:44,Loss:180811.2031\n",
      "Epoch:45,Loss:174254.4531\n",
      "Epoch:46,Loss:168037.1406\n",
      "Epoch:47,Loss:162133.3281\n",
      "Epoch:48,Loss:156516.4844\n",
      "Epoch:49,Loss:151174.5312\n",
      "Epoch:50,Loss:146095.0938\n",
      "Epoch:51,Loss:141259.8281\n",
      "Epoch:52,Loss:136654.2344\n",
      "Epoch:53,Loss:132260.7344\n",
      "Epoch:54,Loss:128066.8047\n",
      "Epoch:55,Loss:124061.2188\n",
      "Epoch:56,Loss:120234.1797\n",
      "Epoch:57,Loss:116576.6953\n",
      "Epoch:58,Loss:113072.3281\n",
      "Epoch:59,Loss:109715.1875\n",
      "Epoch:60,Loss:106497.9531\n",
      "Epoch:61,Loss:103405.1562\n",
      "Epoch:62,Loss:100442.2812\n",
      "Epoch:63,Loss:97597.7812\n",
      "Epoch:64,Loss:94866.1094\n",
      "Epoch:65,Loss:92240.0547\n",
      "Epoch:66,Loss:89715.0312\n",
      "Epoch:67,Loss:87284.6875\n",
      "Epoch:68,Loss:84945.5938\n",
      "Epoch:69,Loss:82689.8438\n",
      "Epoch:70,Loss:80519.8047\n",
      "Epoch:71,Loss:78427.6953\n",
      "Epoch:72,Loss:76409.4453\n",
      "Epoch:73,Loss:74463.5938\n",
      "Epoch:74,Loss:72586.7500\n",
      "Epoch:75,Loss:70777.3125\n",
      "Epoch:76,Loss:69028.8047\n",
      "Epoch:77,Loss:67337.9531\n",
      "Epoch:78,Loss:65698.7422\n",
      "Epoch:79,Loss:64113.9023\n",
      "Epoch:80,Loss:62571.9453\n",
      "Epoch:81,Loss:61079.9062\n",
      "Epoch:82,Loss:59636.1875\n",
      "Epoch:83,Loss:58238.5547\n",
      "Epoch:84,Loss:56887.2031\n",
      "Epoch:85,Loss:55579.2969\n",
      "Epoch:86,Loss:54311.4023\n",
      "Epoch:87,Loss:53081.8125\n",
      "Epoch:88,Loss:51888.9648\n",
      "Epoch:89,Loss:50731.6992\n",
      "Epoch:90,Loss:49608.7070\n",
      "Epoch:91,Loss:48518.9805\n",
      "Epoch:92,Loss:47461.0508\n",
      "Epoch:93,Loss:46434.5391\n",
      "Epoch:94,Loss:45437.4609\n",
      "Epoch:95,Loss:44468.6133\n",
      "Epoch:96,Loss:43528.5859\n",
      "Epoch:97,Loss:42614.0078\n",
      "Epoch:98,Loss:41724.4922\n",
      "Epoch:99,Loss:40859.2539\n",
      "Epoch:100,Loss:40017.1484\n",
      "Epoch:101,Loss:39197.5859\n",
      "Epoch:102,Loss:38400.5117\n",
      "Epoch:103,Loss:37623.7461\n",
      "Epoch:104,Loss:36868.1602\n",
      "Epoch:105,Loss:36132.3828\n",
      "Epoch:106,Loss:35415.4531\n",
      "Epoch:107,Loss:34716.9531\n",
      "Epoch:108,Loss:34036.5156\n",
      "Epoch:109,Loss:33373.5547\n",
      "Epoch:110,Loss:32726.8066\n",
      "Epoch:111,Loss:32096.1875\n",
      "Epoch:112,Loss:31481.1992\n",
      "Epoch:113,Loss:30881.1602\n",
      "Epoch:114,Loss:30296.0957\n",
      "Epoch:115,Loss:29725.5332\n",
      "Epoch:116,Loss:29168.9707\n",
      "Epoch:117,Loss:28626.1699\n",
      "Epoch:118,Loss:28096.5020\n",
      "Epoch:119,Loss:27579.2871\n",
      "Epoch:120,Loss:27074.2402\n",
      "Epoch:121,Loss:26581.3242\n",
      "Epoch:122,Loss:26100.0332\n",
      "Epoch:123,Loss:25629.4746\n",
      "Epoch:124,Loss:25169.8223\n",
      "Epoch:125,Loss:24720.4492\n",
      "Epoch:126,Loss:24281.3633\n",
      "Epoch:127,Loss:23852.3887\n",
      "Epoch:128,Loss:23433.1660\n",
      "Epoch:129,Loss:23023.4062\n",
      "Epoch:130,Loss:22623.1582\n",
      "Epoch:131,Loss:22231.7480\n",
      "Epoch:132,Loss:21848.8555\n",
      "Epoch:133,Loss:21474.3633\n",
      "Epoch:134,Loss:21108.1875\n",
      "Epoch:135,Loss:20750.1172\n",
      "Epoch:136,Loss:20399.6680\n",
      "Epoch:137,Loss:20056.7812\n",
      "Epoch:138,Loss:19721.0977\n",
      "Epoch:139,Loss:19392.4766\n",
      "Epoch:140,Loss:19071.0352\n",
      "Epoch:141,Loss:18756.5859\n",
      "Epoch:142,Loss:18448.6113\n",
      "Epoch:143,Loss:18146.8809\n",
      "Epoch:144,Loss:17851.2930\n",
      "Epoch:145,Loss:17561.7129\n",
      "Epoch:146,Loss:17278.1367\n",
      "Epoch:147,Loss:17000.2910\n",
      "Epoch:148,Loss:16728.0098\n",
      "Epoch:149,Loss:16461.2441\n",
      "Epoch:150,Loss:16199.9463\n",
      "Epoch:151,Loss:15943.7832\n",
      "Epoch:152,Loss:15692.6611\n",
      "Epoch:153,Loss:15446.5801\n",
      "Epoch:154,Loss:15205.4473\n",
      "Epoch:155,Loss:14968.8984\n",
      "Epoch:156,Loss:14738.8770\n",
      "Epoch:157,Loss:14513.9336\n",
      "Epoch:158,Loss:14294.0928\n",
      "Epoch:159,Loss:14078.5645\n",
      "Epoch:160,Loss:13867.0576\n",
      "Epoch:161,Loss:13659.6816\n",
      "Epoch:162,Loss:13456.0371\n",
      "Epoch:163,Loss:13256.2168\n",
      "Epoch:164,Loss:13060.1406\n",
      "Epoch:165,Loss:12867.8965\n",
      "Epoch:166,Loss:12679.0986\n",
      "Epoch:167,Loss:12493.8291\n",
      "Epoch:168,Loss:12311.9502\n",
      "Epoch:169,Loss:12133.3691\n",
      "Epoch:170,Loss:11958.1309\n",
      "Epoch:171,Loss:11786.1582\n",
      "Epoch:172,Loss:11617.1660\n",
      "Epoch:173,Loss:11451.1562\n",
      "Epoch:174,Loss:11288.1533\n",
      "Epoch:175,Loss:11128.0732\n",
      "Epoch:176,Loss:10970.8281\n",
      "Epoch:177,Loss:10816.3838\n",
      "Epoch:178,Loss:10664.7256\n",
      "Epoch:179,Loss:10515.7324\n",
      "Epoch:180,Loss:10369.4980\n",
      "Epoch:181,Loss:10225.7227\n",
      "Epoch:182,Loss:10084.4014\n",
      "Epoch:183,Loss:9945.5830\n",
      "Epoch:184,Loss:9809.1318\n",
      "Epoch:185,Loss:9674.9863\n",
      "Epoch:186,Loss:9543.1709\n",
      "Epoch:187,Loss:9413.6289\n",
      "Epoch:188,Loss:9286.4619\n",
      "Epoch:189,Loss:9161.7129\n",
      "Epoch:190,Loss:9039.0566\n",
      "Epoch:191,Loss:8918.4990\n",
      "Epoch:192,Loss:8799.8691\n",
      "Epoch:193,Loss:8683.2793\n",
      "Epoch:194,Loss:8568.6895\n",
      "Epoch:195,Loss:8456.0186\n",
      "Epoch:196,Loss:8345.2598\n",
      "Epoch:197,Loss:8236.2979\n",
      "Epoch:198,Loss:8129.1387\n",
      "Epoch:199,Loss:8023.6646\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoch_n):\n",
    "    y_pred = x.mm(w1).clamp(min= 0).mm(w2)\n",
    "    loss = (y_pred - y).pow(2).sum()\n",
    "    print(\"Epoch:{},Loss:{:.4f}\".format(epoch, loss.item()))\n",
    "    loss.backward()\n",
    "        \n",
    "    w1.data-= learning_rate*w1.grad.data\n",
    "    w2.data-= learning_rate*w2.grad.data\n",
    "    \n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf00a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
